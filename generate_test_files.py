#!/usr/bin/env python3
"""
Generate test text files for different AI model context windows
"""

import os
import random

def generate_varied_text(target_chars):
    """Generate varied text with different sentence structures"""
    
    # Different types of content to mix
    sentences = [
        "K√ºnstliche Intelligenz revolutioniert unsere moderne Welt auf vielf√§ltige Weise.",
        "Machine Learning algorithms process vast amounts of data to identify patterns.",
        "Die Entwicklung von Large Language Models hat neue M√∂glichkeiten er√∂ffnet.",
        "Natural language processing enables computers to understand human communication.",
        "Transformer-Architekturen haben das Deep Learning grundlegend ver√§ndert.",
        "The attention mechanism allows models to focus on relevant information.",
        "Neuronale Netzwerke lernen komplexe Zusammenh√§nge aus Trainingsdaten.",
        "Fine-tuning pre-trained models accelerates development of specialized applications.",
        "Multimodal AI systems can process text, images, and audio simultaneously.",
        "Die Zukunft der KI liegt in der Kombination verschiedener Modalit√§ten."
    ]
    
    technical_terms = [
        "tokenization", "embeddings", "attention heads", "backpropagation",
        "gradient descent", "neural networks", "deep learning", "reinforcement learning",
        "computer vision", "natural language understanding", "generative AI",
        "foundation models", "transfer learning", "few-shot learning"
    ]
    
    numbers_and_data = [
        "Das Modell wurde mit 1.7 Billionen Parametern trainiert.",
        "Der Datensatz umfasste √ºber 500 Milliarden Tokens.",
        "Training dauerte 2.048 GPU-Stunden auf H100-Chips.",
        "Die Inferenzgeschwindigkeit betr√§gt 50 Tokens pro Sekunde.",
        "Speicherverbrauch: 32 GB VRAM f√ºr Batch-Gr√∂√üe 4."
    ]
    
    text_parts = []
    current_length = 0
    
    while current_length < target_chars:
        # Mix different content types
        content_type = random.choice(['sentence', 'technical', 'data', 'paragraph'])
        
        if content_type == 'sentence':
            part = random.choice(sentences)
        elif content_type == 'technical':
            part = f"In der KI-Entwicklung spielt {random.choice(technical_terms)} eine zentrale Rolle bei der Optimierung von Modellarchitekturen."
        elif content_type == 'data':
            part = random.choice(numbers_and_data)
        else:  # paragraph
            part = " ".join(random.choices(sentences, k=3)) + "\n\n"
        
        text_parts.append(part + " ")
        current_length += len(part) + 1
        
        # Add occasional line breaks for readability
        if random.random() < 0.1:
            text_parts.append("\n")
            current_length += 1
    
    return "".join(text_parts)[:target_chars]

def create_test_files():
    """Create test files for different AI models"""
    
    # Ensure test directory exists
    os.makedirs("test_files", exist_ok=True)
    
    test_configs = [
        {
            "name": "gpt4o_max_context",
            "filename": "gpt4o_128k_context.txt", 
            "description": "GPT-4o max context (128K tokens ‚âà 512K chars)",
            "target_chars": 512000
        },
        {
            "name": "claude_sonnet4_max_context", 
            "filename": "claude_sonnet4_200k_context.txt",
            "description": "Claude Sonnet 4 max context (200K tokens ‚âà 760K chars)", 
            "target_chars": 760000
        },
        {
            "name": "gemini25pro_large_context",
            "filename": "gemini25pro_1m_context.txt",
            "description": "Gemini 2.5 Pro large context (1M tokens ‚âà 4M chars)",
            "target_chars": 4000000
        },
        {
            "name": "medium_test",
            "filename": "medium_50k_test.txt",
            "description": "Medium test file (~12.5K tokens ‚âà 50K chars)",
            "target_chars": 50000
        },
        {
            "name": "small_test", 
            "filename": "small_10k_test.txt",
            "description": "Small test file (~2.5K tokens ‚âà 10K chars)",
            "target_chars": 10000
        }
    ]
    
    print("üöÄ Generating AI model test files...\n")
    
    for config in test_configs:
        print(f"üìù Creating {config['filename']}...")
        print(f"   Target: {config['target_chars']:,} characters")
        print(f"   Description: {config['description']}")
        
        # Generate content
        content = generate_varied_text(config['target_chars'])
        
        # Add header with file info
        header = f"""# AI Token Calculator Test File
# File: {config['filename']}
# Description: {config['description']}
# Generated characters: {len(content):,}
# Estimated tokens (√∑4): ~{len(content)//4:,}
# Generated by: AI Token Calculator Test Generator

"""
        
        # Write file
        filepath = os.path.join("test_files", config['filename'])
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(header + content)
        
        # Verify file
        actual_size = len(header + content)
        print(f"   ‚úÖ Generated: {actual_size:,} characters (~{actual_size//4:,} tokens)")
        print(f"   üìÅ Saved to: {filepath}\n")
    
    print("üéâ All test files generated successfully!")
    print("\nüìã Usage:")
    print("1. Upload these files in the 'Dateien' tab of the Token Calculator")
    print("2. Compare results with actual AI chat interfaces")
    print("3. Test real chat limits vs our calculator predictions")

if __name__ == "__main__":
    create_test_files()